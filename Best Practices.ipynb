{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices\n",
    "\n",
    "This document collects some of the best practices used elsewhere in the pandas documentation.\n",
    "Together, they lead to a style of code lovingly referred to as *pandorable*. We encourage\n",
    "you to apply these practicies when using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use method chaining\n",
    "\n",
    "Compare the following two stories (credit to [Jeff Allen](http://trestletech.com/wp-content/uploads/2015/07/dplyr.pdf)):\n",
    "\n",
    "First,\n",
    "\n",
    "```python\n",
    "on_hill = went_up(jack_jill, 'hill')\n",
    "with_water = fetch(on_hill, 'water')\n",
    "fallen = fell_down(with_water, 'jack')\n",
    "broken = broke(fallen, 'jack')\n",
    "after = tmple_after(broken, 'jill')\n",
    "```\n",
    "\n",
    "and second,\n",
    "\n",
    "```python\n",
    "(jack_jill\n",
    "    .went_up(\"hill\")\n",
    "    .fetch(\"water\")\n",
    "    .fell_down(\"jack\")\n",
    "    .broke(\"crown\")\n",
    "    .tumble_after(\"jill\"))\n",
    "```\n",
    "\n",
    "I hope you agree that the second story, written in a method chaining style, is easier to follow. It avoids uninteresting intermediate variables, generally making things easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a concrete example, we'll look at the light pre-procesing done to the `airports` datset following Hadley Wickham's [nycflights13 package](https://github.com/hadley/nycflights13/blob/master/data-raw/airports.R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"id\", \"name\", \"city\", \"country\", \"faa\", \"icao\", \"lat\", \"lon\", \"alt\", \"tz\", \"dst\", \"tzone\"]\n",
    "\n",
    "airports_raw = pd.read_csv(\"https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.dat\",\n",
    "                           header=None, names=names)\n",
    "airports_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a bit of cleaning up including filtering the rows and columns to the values of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = (\n",
    "    airports_raw\n",
    "        .loc[lambda df: (df['country'] == 'United States') & (df['faa'] != '')]\n",
    "        [['faa', 'name', 'lat', 'lon', 'alt', 'tz', 'dst', 'tzone']]\n",
    "        .drop_duplicates(subset=\"faa\")\n",
    "        .set_index(\"faa\")\n",
    ")\n",
    "airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Series or DataFrame methods return a new Series or DataFrame, encouraging this method chaining style. Some notable methods include\n",
    "\n",
    "1. :meth:`DataFrame.assign`\n",
    "2. :meth:`DataFrame.loc`, :meth:`DataFrame.iloc`, :meth:`DataFrame.where`, and ``DataFrame.__getitem__`.\n",
    "3. :meth:`DataFrame.pipe`\n",
    "\n",
    "One thing to note, the `assign` and indexing methods will accept callables, which you use to refer to the previous link in the method chain. Consider translating an imperative string of operations like\n",
    "\n",
    "```python\n",
    "df1 = pd.read_csv(...)\n",
    "df1['foo'] = df1['foo'].str.upper()\n",
    "df1 = df1.loc[df['bar'] > 3]\n",
    "```\n",
    "\n",
    "to method chaining style. You'd use callables, often `lambda` functions, to refer to `df1` in subsequent operations.\n",
    "\n",
    "```python\n",
    "df = (\n",
    "    pd.read_csv(...)\n",
    "    .assign(foo=lambda df: df[\"foo\"].str.upper())\n",
    "    .loc[lambda df: df[\"bar\"] > 3]\n",
    ")\n",
    "```\n",
    "\n",
    "Finally, pandas provides an escape hatch through the `.pipe` method. With `.pipe`, you can provide any callable that expects a DataFrame (or Series) as it's first argument. For example, we could implement a function approximating the great circle distance between some airport `to` and the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def great_circle_distance(df, to=\"DSM\"):\n",
    "    # https://www.johndcook.com/blog/python_longitude_latitude/\n",
    "    df = df.copy()\n",
    "    lat = np.deg2rad(90 - df['lat'])\n",
    "    lon = np.deg2rad(90 - df['lon'])\n",
    "    \n",
    "    to_lat, to_lon = df.loc[to, ['lat', 'lon']]\n",
    "    cos = (np.sin(lat) * np.sin(to_lat) * np.cos(lon - to_lon) +\n",
    "           np.cos(lat) * np.cos(to_lat))\n",
    "\n",
    "    arc = np.arccos(cos)\n",
    "    kilometers = 6373 * cos\n",
    "    df[f'km_to_{to}'] = kilometers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_circle_distance(airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our custom `great_circle_distance` function further encourages method chaining by returning a DataFrame itself.\n",
    "\n",
    "Appending that to our original method chain, that would be\n",
    "\n",
    "```python\n",
    "airports = (\n",
    "    airports_raw\n",
    "        .loc[lambda df: (df['country'] == 'United States') & (df['faa'] != '')]\n",
    "        [['faa', 'name', 'lat', 'lon', 'alt', 'tz', 'dst', 'tzone']]\n",
    "        .drop_duplicates(subset=\"faa\")\n",
    "        .set_index(\"faa\")\n",
    "        .pipe(gcd)\n",
    ")\n",
    "```\n",
    "\n",
    "Additional keyword arguments passed to `.pipe` are passed through to the callable.\n",
    "\n",
    "```python\n",
    "airports = (\n",
    "    ...\n",
    "    .pipe(gcd, to=\"ORD\")\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Meaningful Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every Series and DataFrame has a `.index` property storing the *row labels*.\n",
    "Additionally, DataFrame has the `.columns` property for storing *column labels*.\n",
    "\n",
    "We recommend that you use meaningful labels. Pandas' most fundamental operations *align by label*. Constructors, binary options (`add`, `mul`, etc.), reshaping (`concat`), etc. all align before doing an operation.\n",
    "\n",
    "Let's consider a simple example computing population density from two datasets (https://jakevdp.github.io/PythonDataScienceHandbook/03.03-operations-in-pandas.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.DataFrame([\n",
    "    ('Alaska', 1723337),\n",
    "    ('Texas', 695662),\n",
    "    ('California', 423967)\n",
    "], columns=['state', 'area'])\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.DataFrame([\n",
    "    ('California', 38332521),\n",
    "    ('Texas', 26448193),\n",
    "    ('New York', 19651127),\n",
    "], columns=['state', 'population'])\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we naively divide the population column by the area column, we get incorrect results, and it's unclear which population values go with which state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['population'] / area['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be better to model this problem as two Series, each with the `state` as its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ = area.set_index(\"state\")['area']\n",
    "population_ = population.set_index(\"state\")[\"population\"]\n",
    "population_ / area_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses row labels (and column labels for DataFrames) to align the data before doing the operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid duplicate row and column labels\n",
    "\n",
    "One of pandas' primary roles is to help clean up messy tabular data. So while pandas *can* store duplicate labels, we recommend addressing duplicate labels as early as possible to avoid surpsises later on. Consider one of pandas' most basic opertions: selecting a value from a DataFrame. Duplicate labels can change the behavior in surprising ways.\n",
    "\n",
    "Pandas follows the NumPy tradition of *reducing dimensionality* when indexing. Slicing a row from a 2-D array returns a 1-D array. Slicing a row and a column returns a scalar. Similarly with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.loc['BFT', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, when there are duplicates in the index, it's no longer possible to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_duplicated = airports_raw.set_index('faa')\n",
    "airports_duplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_duplicated.loc['BFT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are *two* rows with the code `FAA`, meaning the `.loc['BFT']` returns a DataFrame, rather than a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index.duplicated\n",
    "airports_deduplicated = airports_duplicated[~airports_duplicated.index.duplicated()]\n",
    "airports_deduplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_deduplicated.loc['BFT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid Inplace Operations\n",
    "\n",
    "For many operations, Pandas current memory model doesn't allow true inplace (zero copy) operations.\n",
    "The reasons are complicated, and we hope to address them someday, but the upshot is that `inplace=True` rarely means zero-copy.\n",
    "\n",
    "Consider :meth:`DataFrame.fillna`. That requires checking for missing values and applying a boolean mask, selecting just the rows with no NA values. Even in NumPy, boolean indexing takes a copy of the data, and not a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_inplace = airports_raw.copy()\n",
    "airports_inplace.dropna(inplace=True)\n",
    "airports_inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual operation is the same, regardless of whether `inplace=True` or `inplace=False`. The only difference is whether a new `DataFrame` object is returned, or whether your reference is updated inplace. For these types of methods, the only benefit of `inplace=True` is to avoid having to type the name of your object twice\n",
    "\n",
    "```python\n",
    "really_long_dataframe_name = really_long_dataframe_name.dropna()\n",
    "\n",
    "# vs.\n",
    "\n",
    "really_long_dataframe_name.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "But we recommend using method chaining, which avoids the need to type the name of the object twice in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid `.values`\n",
    "\n",
    "``DataFrame.values`` is a surprising complex attribute. The main goal is to get a NumPy representation of the data backing the DataFrame. This can be useful if you're doing lower-level numerical operations, or working with a library that needs an ndarray rather than a DataFrame.\n",
    "\n",
    "In the simplest case, ``.values`` really does return a view on the data stored inside a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = np.random.randn(4, 3)\n",
    "df = pd.DataFrame(raw, columns=['a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values.base is raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, whenever you're mixing mulitple dtypes (which is kind of the point of pandas), `.values` ceases to be a simple view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.Categorical(['a', 'b', 'c', 'd'])\n",
    "df['d'] = cat\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays have a single dtype for every element, which means we must find a common dtype for all the columns. In practice, this often means `object`-dtype (each element of the 2D array is a Python object). This conversion from native to object dtype is expensive in time and memory.\n",
    "\n",
    "If you need a NumPy array from a DataFrame, we recommend using :meth:`DataFrame.to_numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it clearer that the operation may be expensive (and offers control over whether or not to copy the data).\n",
    "\n",
    "For :class:`Series` things are both simpler and more complex. We no longer have the issue with having to find a common dtype to accomodate multiple columns. However, not every 1-D array allowed in Pandas can be represented by NumPy.\n",
    "\n",
    "The basics like floats are fine. And we get zero-copy access to the the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'].values.base is raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for extension types, this isn't necessarily true. We have two conflicting desires\n",
    "\n",
    "1. Get a NumPy representation of the data\n",
    "2. Get a zero-copy view on the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = pd.array(['2000', '2001', '2002', '2003'], dtype='Period[D]')\n",
    "df['e'] = periods\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['e'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first purpose, we recommend :meth:`Series.to_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['e'].to_numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the second purpose, we recommend :meth:`Series.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['e'].array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See :ref:`dsintro.arraylike` for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Tidy Data Principles\n",
    "\n",
    "As [Hadley Whickham](http://www.jstatsoft.org/v59/i10/paper) says, Tidy Data is about\n",
    "\n",
    "> Structuring datasets to facilitate analysis\n",
    "\n",
    "His three rules are that a dataset is tidy when\n",
    "\n",
    "1. Each variable forms a column\n",
    "2. Each observation forms a row\n",
    "3. Each type of observational unit forms a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(\"http://www.basketball-reference.com/leagues/NBA_2016_games.html\")\n",
    "games = tables[0]\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'Date': 'date', 'Start (ET)': 'start',\n",
    "                'Unamed: 2': 'box', 'Visitor/Neutral': 'away_team', \n",
    "                'PTS': 'away_points', 'Home/Neutral': 'home_team',\n",
    "                'PTS.1': 'home_points', 'Unamed: 7': 'n_ot'}\n",
    "\n",
    "games = (games.rename(columns=column_names)\n",
    "    .dropna(thresh=4)\n",
    "    [['date', 'away_team', 'away_points', 'home_team', 'home_points']]\n",
    "    .assign(date=lambda x: pd.to_datetime(x['date'], format='%a, %b %d, %Y'))\n",
    "    .set_index('date', append=True)\n",
    "    .rename_axis([\"game_id\", \"date\"])\n",
    "    .sort_index())\n",
    "games.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the question **How many days of rest did each team get between each game?**\n",
    "As currently structed, our dataset does not facilitate answering that question. A single team's games are spread across multiple columns (`away_team`, `home_team`).\n",
    "\n",
    "To answer this question, the columns would be something like\n",
    "\n",
    "date       | team_name\n",
    "---------- | ---------------\n",
    "2015-10-27 | Detroit Pistons\n",
    "2015-10-27 | Atlanta Hawks\n",
    "2015-10-27 | Cleveland Cavaliers\n",
    "...        | ...\n",
    "\n",
    "We acheive that with :meth:`DataFrame.melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = (games.reset_index()\n",
    "    .melt(id_vars=['game_id', 'date'], value_vars=['away_team', 'home_team'],\n",
    "          value_name='team', var_name='home_or_away')\n",
    ")\n",
    "tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now answering the question is relatively straightforward. For each team (`.groupby('team')`), how many days passed between rows (`.date.diff().dt.days - 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.groupby('team')['date'].diff().dt.days - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
